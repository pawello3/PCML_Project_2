{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_file_path = \"data_train.csv\"\n",
    "ratings = load_data(dataset_file_path)\n",
    "print('Shape of ratings matrix:', ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plots import plot_raw_data\n",
    "\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_MF_random(train, num_features):\n",
    "    \"\"\"\n",
    "        Initialize randomly the matrices W and Z of matrix factorization.\n",
    "\n",
    "        Arguments:\n",
    "            train: training set (matrix X)\n",
    "            num_features: number of latent variables in the W*Z^T decomposition\n",
    "\n",
    "        Returned value(s):\n",
    "            item_features: matrix W of shape = num_features, num_item\n",
    "            user_features: matrix Z of shape = num_features, num_user\n",
    "    \"\"\"\n",
    "    \n",
    "    item_features = np.random.random((train.shape[0],num_features)) # W matrix initialization\n",
    "    user_features = np.random.random((train.shape[1],num_features)) # Z matrix initialization\n",
    "    \n",
    "    return item_features, user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define parameters\n",
    "num_features = 2 # number of latent features in matrix factorization\n",
    "lambda_item = 0.0 # regularization parameter for item features\n",
    "lambda_user = 0.0 # regularization parameter for user features\n",
    "num_epochs = 20 # number of iterations of ALS\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(988)\n",
    "\n",
    "# initialize matrices W and Z\n",
    "item_features, user_features = init_MF_random(ratings, num_features)\n",
    "\n",
    "# find the non-zero ratings indices in the training set\n",
    "nz_row, nz_col = ratings.nonzero()\n",
    "nz_train = list(zip(nz_row, nz_col))\n",
    "\n",
    "# initialize matrices used to compute RMSE\n",
    "train_label = np.zeros(len(nz_train))\n",
    "prediction_label = np.zeros(len(nz_train))\n",
    "\n",
    "# initialize accumulator for RMSE of every iteration\n",
    "rmse_train = np.zeros(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_ALS(ratings, item_features, user_features, num_features, num_epochs):\n",
    "    for it in range(num_epochs):\n",
    "        begin = datetime.datetime.now() # start time measurement\n",
    "\n",
    "        user_features = ((np.linalg.inv((item_features.T.dot(item_features) + lambda_user * np.identity(num_features)))).dot(item_features.T.dot(ratings))).T\n",
    "        print(\"Items\")\n",
    "        item_features = ((np.linalg.inv((user_features.T.dot(user_features) + lambda_item * np.identity(num_features)))).dot(user_features.T.dot(ratings.T))).T\n",
    "\n",
    "        end = datetime.datetime.now() # stop time measurement\n",
    "\n",
    "        # calculate training rmse\n",
    "        for i in range(len(nz_train)):\n",
    "            train_label[i] = ratings[nz_train[i][0], nz_train[i][1]]\n",
    "            prediction_label[i] = item_features[nz_train[i][0], :].dot(user_features[nz_train[i][1], :])\n",
    "\n",
    "        # store RMSE of current iteration\n",
    "        rmse_train[it] = calculate_mse(train_label, prediction_label)\n",
    "        print(\"Epoch: {}, RMSE on training set: {}\".format(it, rmse_train[it]))\n",
    "\n",
    "        # compute the time of the iteration\n",
    "        execution_time = (end - begin).total_seconds()\n",
    "        print(\"Execution time:\", execution_time)\n",
    "\n",
    "        print(\"*\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_ALS(ratings, item_features, user_features, num_features, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_csv_submission(user_features, item_features)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
